# RAG-система для компании EORA

## Описание проекта

Данное приложение реализует следующий функционал:
- Предоставляет релевантные ответы на вопросы пользователей о компании
- Предоставляет доступ через Telegram-бот и CLI интерфейс

## Этапы запуска проекта

### 1. Подготовка окружения

```bash
# Клонирование репозитория
git clone https://github.com/dreamLogicc/eora_test.git
cd eora_test

# Создание виртуального окружения
python -m venv .venv
source .venv/bin/activate  

# Установка зависимостей
pip install -r requirements.txt
```

### 2. Настройка переменных окружения

Создайте файл `.env` на основе `.env.template`:

```bash
cp .env.template .env
```

Заполните необходимые токены в `.env`:
```
HF_TOKEN=your_huggingface_token_here
GIGACHAT_CLIENT_SECRET=your_gigachat_secret_here
BOT_TOKEN=your_telegram_bot_token_here
```

### 3. Получение токенов

**HuggingFace Token:**
- Зарегистрируйтесь на [huggingface.co](https://huggingface.co)
- Создайте токен в Settings → Access Tokens

**GigaChat Secret:**
- Получите доступ к API GigaChat
- Сгенерируйте client_secret в личном кабинете

**Telegram Bot Token:**
- Создайте бота через [@BotFather](https://t.me/botfather)
- Получите токен для API

### 4. Запуск приложения

**Вариант 1 - CLI интерфейс:**
```bash
python src/cli.py
```

**Вариант 2 - Telegram бот:**
```bash
python src/bot.py
```

### 5. Первый запуск

При первом запуске система:
1. Загрузит эмбеддинговую модель Qwen/Qwen3-Embedding-0.6B
2. Создаст векторную базу данных ChromaDB
3. Если `data.json` отсутствует, запарсит все ссылки из `links.py`
4. Создаст индексы для семантического поиска

## Что можно добавить в решение

### Технические улучшения

1. **Расширение функциональности**
   - Интеграция с другими LLM (OpenAI GPT, Claude)
   - Добавление фильтрации по категориям проектов
   - Система обратной связи от пользователей (Оценка ответа)

2. **Улучшение качества ответов**
   - Fine-tuning эмбеддинговой модели на доменных данных либо поиск более подходящей
   - Использование различных стратегий разбивания текста на чанки
   - Добавление контекстных метаданных (дата, тип проекта, технологии)
   - Улучшение промпта для языковой модели

3. **Масштабируемость**
   - Переход на Qdrant
   - Добавление возможности контейнеризации с помощью Docker
   - Настройка CI/CD

## Проверка качества RAG

Качество RAG я проверял эвристически, задавал вопросы по конкретному проекту и смотрел на выдаваемый ответ, затем сравнивал с ифнормацией на сайте. Такой подход, очевидно, не лишен недостаков. 
Опишу как я бы поверял качество RAG если бы было больше времени:

1. Оценка Precision и Recall
- Составить запросы и для каждого запроса подобрать эталонные документы. Затем вычилить Precision и Recall.

2. Оценка генерации через LLM
- Использовать более сильную модель как судью. На вход ей подавать запрос, сгенерированный ответ и эталонный ответ.

3. Если внедрить оценку качества ответов, то, очевидно, можно смотреть по оценкам ответов.

## Пример работы приложения

![](https://github.com/dreamLogicc/eora_test/blob/f2d27d6c4b12a1f984833d932f9eca8cfae618de/cli-example.png)
![](https://github.com/dreamLogicc/eora_test/blob/f2d27d6c4b12a1f984833d932f9eca8cfae618de/telegram-example.png)

